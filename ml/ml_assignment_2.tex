\documentclass[a4paper,11pt]{jsarticle}


% 数式
\usepackage{amsmath,amsfonts}
\usepackage{bm}
\usepackage{physics}
% 画像
\usepackage[dvipdfmx]{graphicx}
% ローマ数字
\usepackage{otf}
% 単位
\usepackage{siunitx}
% 表
\usepackage{multirow}
% 化学反応
\usepackage[version=4]{mhchem}


\begin{document}

\title{機械学習概論　第2回レポート}
\author{05-211525　齋藤駿一}
\date{\today}
\maketitle

\section{前処理}
まず，訓練データ（dry\_bean\_train\_data.csv）およびテストデータ（dry\_bean\_test\_data.csv）の要素を次のように前処理した．

\begin{enumerate}
  \item 17個の特徴量の数値をそれぞれ，平均0，分散1となるように変換した．
  \item 7つの種類を0から6までの整数値に変換した．
\end{enumerate}

\section{サポートベクトルマシンによる学習}

まず，訓練データを用いてサポートベクトルマシン（SVM）の学習を行い，テストデータの特徴量からその種類を推測させた．
その際，SVMのカーネルは線形カーネルとした．
また，コストパラメータ$C$とカーネル幅$\gamma$は$10^{a}\,(a=-3,-2,-1,0,1,2)$の中から選び，訓練データを用いて10-foldの交差検証を行い，最適と判断された量を採用した．

その結果，交差検証での正答率は92.4\%，テストデータでの正答率は93.1\%となった．

\section{多層ニューラルネットによる学習}

次に，SVMのかわりに多層ニューラルネットを用いて学習を行った．
前処理として，訓練データとテストデータにおいて，7つの種類をone-hot codingに直した．
ここでは，以下ようにニューラルネットを構築した．
まず，入力ユニット16個（特徴量の数と同じ）を30個の中間ユニットに全結合させ，その活性化関数をtahnとした．
次に，その中間ユニットを7個（種類の数と同じ）の出力ユニットに全結合させ，その活性化関数をsoftmaxとした．
また，損失関数は交差エントロピーとし，最適化アルゴリズムはSGDとした．
そして，これをバッチサイズ10で300エポックの間学習させた．

その結果，最終的な正答率は，訓練データで94.4\%，テストデータで93.6\%となった．

その後，バッチを正規化したり，層の数を増やしたり，Early stopping（訓練データを9:1に分割して前者を学習に用い，後者を過学習する前に学習を止めるために用いる）をしたりすることで，精度の向上を試みた．
しかし，訓練データを減らしたことによる精度の低下のため，上述の精度を超えられなかった．

また，ガウス過程を用いて学習させることも試したが，こちらは計算時間が非常に長くなってしまい，断念した．

\end{document}